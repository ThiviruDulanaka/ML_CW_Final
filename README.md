# CM2604 Machine Learning: Bank Term Deposit Subscription Prediction

This repository contains the individual coursework submission for the **CM2604 Machine Learning** module at Robert Gordon University.

The project focuses on a classification problem: predicting whether a client will subscribe to a term deposit based on the 'Bank Marketing' dataset. [cite_start]The implementation is governed by Git as required[cite: 15, 24].

## Coursework Information

| Detail | Information |
| --- | --- |
| **University** | [cite_start]Robert Gordon University [cite: 1] |
| **Module** | [cite_start]CM2604 Machine Learning [cite: 4] |
| **Module Coordinator** | [cite_start]Sahan Priyanayana [cite: 4] |
| **Assessment** | [cite_start]Coursework (Individual) [cite: 4] |
| **Academic Year** | [cite_start]2024/2025 [cite: 4] |
| **Deadline** | [cite_start]29th July 2025 23:59 Hrs [cite: 4] |

## ðŸŽ¯ Project Objective

[cite_start]The primary goal is to build and evaluate two machine learning models to solve a classification problem: **Predicting if a client will subscribe to a term deposit**[cite: 15].

* [cite_start]**Dataset:** 'Bank Marketing' dataset from the UCI Machine Learning Repository[cite: 16].
* **Models Required:**
    1.  [cite_start]Decision Tree Algorithm [cite: 17]
    2.  [cite_start]Neural Network [cite: 17]

[cite_start]The project follows the full machine learning pipeline, from data preparation to model comparison[cite: 19, 21].

## Methodology

[cite_start]The project implementation is structured around the key grading criteria outlined in the assessment brief[cite: 45].

### 1. Corpus Preparation (20%)
* [cite_start]Loading the 'Bank Marketing' dataset[cite: 16].
* [cite_start]Applying optimal strategies for data cleaning, preprocessing, and feature engineering to prepare the dataset for the models[cite: 19]. [cite_start]This satisfies Learning Outcome 1[cite: 8].

### 2. Implementation (30%)
* [cite_start]Building two distinct classification models using appropriate libraries and frameworks[cite: 20].
    * [cite_start]**Model 1:** Decision Tree [cite: 17]
    * [cite_start]**Model 2:** Neural Network [cite: 17]

### 3. Experiments (25%)
* [cite_start]Designing and running experiments for both models[cite: 22].
* [cite_start]Comparing the implemented models using optimal evaluation metrics suitable for the classification task[cite: 21]. [cite_start]This contributes to Learning Outcome 2[cite: 9].

### 4. Discussion (25%)
* [cite_start]Showcasing and analyzing the experimental results[cite: 22].
* [cite_start]A full discussion of the findings, model comparison, solution methodology, limitations, and potential future enhancements is included in the final report[cite: 24].

## ðŸ“‚ Repository Structure
